08-30 22:23:55 method: DA
08-30 22:23:55 model_name: ALSTMAdFeatures
08-30 22:23:55 data_name: Battery
08-30 22:23:55 data_dir: ../processed
08-30 22:23:55 transfer_task: [[1], [0]]
08-30 22:23:55 normlizetype: mean-std
08-30 22:23:55 adabn: False
08-30 22:23:55 eval_all: False
08-30 22:23:55 adabn_epochs: 3
08-30 22:23:55 cuda_device: 0
08-30 22:23:55 checkpoint_dir: ./checkpoint
08-30 22:23:55 pretrained: False
08-30 22:23:55 batch_size: 128
08-30 22:23:55 num_workers: 0
08-30 22:23:55 seed: 3
08-30 22:23:55 patience: 50
08-30 22:23:55 bottleneck: True
08-30 22:23:55 bottleneck_num: 128
08-30 22:23:55 last_batch: False
08-30 22:23:55 distance_metric: True
08-30 22:23:55 distance_loss: JMMD
08-30 22:23:55 trade_off_distance: Step
08-30 22:23:55 lam_distance: 1.2
08-30 22:23:55 domain_adversarial: False
08-30 22:23:55 adversarial_loss: CDA
08-30 22:23:55 hidden_size: 1024
08-30 22:23:55 trade_off_adversarial: Step
08-30 22:23:55 lam_adversarial: 2
08-30 22:23:55 opt: adam
08-30 22:23:55 lr: 0.001
08-30 22:23:55 momentum: 0.9
08-30 22:23:55 weight_decay: 1e-05
08-30 22:23:55 lr_scheduler: step
08-30 22:23:55 gamma: 0.8
08-30 22:23:55 steps: 80, 95, 105
08-30 22:23:55 criterion: CeLoss
08-30 22:23:55 middle_epoch: 25
08-30 22:23:55 max_epoch: 50
08-30 22:23:55 print_step: 600
08-30 22:23:55 wandb: True
08-30 22:23:55 using 1 gpus

100%|██████████| 3/3 [00:04<00:00,  1.58s/it]


100%|██████████| 3/3 [00:04<00:00,  1.54s/it]
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [128, 3]                  --
├─ALSTMAdFeatures: 1-1                   [128, 128]                --
│    └─Sequential: 2-1                   [128, 60, 300]            --
│    │    └─Conv1d: 3-1                  [128, 32, 300]            2,720
│    │    └─ReLU: 3-2                    [128, 32, 300]            --
│    │    └─Conv1d: 3-3                  [128, 60, 300]            5,820
│    │    └─ReLU: 3-4                    [128, 60, 300]            --
│    └─GRU: 2-2                          [128, 300, 64]            124,800
│    └─GRU: 2-3                          [128, 300, 32]            27,072
│    └─Sequential: 2-4                   [128, 300, 1]             --
│    │    └─Linear: 3-5                  [128, 300, 16]            528
│    │    └─ReLU: 3-6                    [128, 300, 16]            --
│    │    └─Linear: 3-7                  [128, 300, 1]             16
│    │    └─Softmax: 3-8                 [128, 300, 1]             --
│    └─Linear: 2-5                       [128, 2048]               19,662,848
│    └─Linear: 2-6                       [128, 128]                262,272
├─Sequential: 1-2                        [128, 128]                --
│    └─Linear: 2-7                       [128, 128]                16,512
│    └─ReLU: 2-8                         [128, 128]                --
│    └─Dropout: 2-9                      [128, 128]                --
├─Linear: 1-3                            [128, 3]                  387
==========================================================================================
Total params: 20,102,975
Trainable params: 20,102,975
Non-trainable params: 0
Total mult-adds (G): 8.71
==========================================================================================
Input size (MB): 1.84
Forward/backward pass size (MB): 65.34
Params size (MB): 80.41
Estimated Total Size (MB): 147.59
==========================================================================================
Model build successfully!
08-30 22:24:11 ==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [128, 3]                  --
├─ALSTMAdFeatures: 1-1                   [128, 128]                --
│    └─Sequential: 2-1                   [128, 60, 300]            --
│    │    └─Conv1d: 3-1                  [128, 32, 300]            2,720
│    │    └─ReLU: 3-2                    [128, 32, 300]            --
│    │    └─Conv1d: 3-3                  [128, 60, 300]            5,820
│    │    └─ReLU: 3-4                    [128, 60, 300]            --
│    └─GRU: 2-2                          [128, 300, 64]            124,800
│    └─GRU: 2-3                          [128, 300, 32]            27,072
│    └─Sequential: 2-4                   [128, 300, 1]             --
│    │    └─Linear: 3-5                  [128, 300, 16]            528
│    │    └─ReLU: 3-6                    [128, 300, 16]            --
│    │    └─Linear: 3-7                  [128, 300, 1]             16
│    │    └─Softmax: 3-8                 [128, 300, 1]             --
│    └─Linear: 2-5                       [128, 2048]               19,662,848
│    └─Linear: 2-6                       [128, 128]                262,272
├─Sequential: 1-2                        [128, 128]                --
│    └─Linear: 2-7                       [128, 128]                16,512
│    └─ReLU: 2-8                         [128, 128]                --
│    └─Dropout: 2-9                      [128, 128]                --
├─Linear: 1-3                            [128, 3]                  387
==========================================================================================
Total params: 20,102,975
Trainable params: 20,102,975
Non-trainable params: 0
Total mult-adds (G): 8.71
==========================================================================================
Input size (MB): 1.84
Forward/backward pass size (MB): 65.34
Params size (MB): 80.41
Estimated Total Size (MB): 147.59
==========================================================================================
08-30 22:24:11 -----Epoch 0/49-----
08-30 22:24:11 current lr: [0.001, 0.001, 0.001]
08-30 22:24:12 Epoch: 0 [0/7172], Train Loss: 1.0878 Train Acc: 0.3828,128.5 examples/sec 1.00 sec/batch
Isc recall: 0
08-30 22:24:15 Epoch: 0 source_train-Loss: 0.8385 source_train-Acc: 0.5935, Cost 4.2 sec
08-30 22:24:15 Epoch: 0 source_val-Loss: 0.5578 source_val-Acc: 0.7777, Cost 0.3 sec
08-30 22:24:16 Epoch: 0 target_val-Loss: 0.6206 target_val-Acc: 0.7523, Cost 0.4 sec
08-30 22:24:16 -----Epoch 1/49-----
08-30 22:24:16 current lr: [0.001, 0.001, 0.001]
08-30 22:24:19 Epoch: 1 source_train-Loss: 0.5451 source_train-Acc: 0.7899, Cost 3.1 sec
Isc recall: 0
08-30 22:24:19 Epoch: 1 source_val-Loss: 0.5281 source_val-Acc: 0.7946, Cost 0.3 sec
08-30 22:24:19 Epoch: 1 target_val-Loss: 0.5460 target_val-Acc: 0.8020, Cost 0.4 sec
08-30 22:24:19 -----Epoch 2/49-----
08-30 22:24:19 current lr: [0.001, 0.001, 0.001]
08-30 22:24:22 Epoch: 2 source_train-Loss: 0.5341 source_train-Acc: 0.7937, Cost 3.1 sec
08-30 22:24:23 Epoch: 2 source_val-Loss: 0.5281 source_val-Acc: 0.7946, Cost 0.3 sec
Isc recall: 0
08-30 22:24:23 Epoch: 2 target_val-Loss: 0.5450 target_val-Acc: 0.8006, Cost 0.4 sec
08-30 22:24:23 -----Epoch 3/49-----
08-30 22:24:23 current lr: [0.001, 0.001, 0.001]
08-30 22:24:26 Epoch: 3 source_train-Loss: 0.5339 source_train-Acc: 0.7948, Cost 3.1 sec
08-30 22:24:27 Epoch: 3 source_val-Loss: 0.5277 source_val-Acc: 0.7946, Cost 0.3 sec
08-30 22:24:27 Epoch: 3 target_val-Loss: 0.5253 target_val-Acc: 0.8043, Cost 0.4 sec
08-30 22:24:27 -----Epoch 4/49-----
08-30 22:24:27 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
Isc recall: 0
08-30 22:24:30 Epoch: 4 source_train-Loss: 0.5307 source_train-Acc: 0.7948, Cost 3.0 sec
08-30 22:24:30 Epoch: 4 source_val-Loss: 0.5213 source_val-Acc: 0.7949, Cost 0.2 sec
08-30 22:24:31 Epoch: 4 target_val-Loss: 0.5395 target_val-Acc: 0.7958, Cost 0.4 sec
08-30 22:24:31 -----Epoch 5/49-----
08-30 22:24:31 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:24:34 Epoch: 5 source_train-Loss: 0.9819 source_train-Acc: 0.4950, Cost 3.0 sec
08-30 22:24:34 Epoch: 5 source_val-Loss: 1.0599 source_val-Acc: 0.4453, Cost 0.3 sec
08-30 22:24:34 Epoch: 5 target_val-Loss: 1.0542 target_val-Acc: 0.4496, Cost 0.4 sec
08-30 22:24:34 -----Epoch 6/49-----
08-30 22:24:34 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:24:37 Epoch: 6 source_train-Loss: 1.0620 source_train-Acc: 0.4453, Cost 3.0 sec
08-30 22:24:38 Epoch: 6 source_val-Loss: 1.0598 source_val-Acc: 0.4456, Cost 0.3 sec
08-30 22:24:38 Epoch: 6 target_val-Loss: 1.0543 target_val-Acc: 0.4505, Cost 0.4 sec
08-30 22:24:38 -----Epoch 7/49-----
08-30 22:24:38 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:24:41 Epoch: 7 source_train-Loss: 1.0614 source_train-Acc: 0.4457, Cost 3.1 sec
08-30 22:24:41 Epoch: 7 source_val-Loss: 1.0618 source_val-Acc: 0.4456, Cost 0.4 sec
08-30 22:24:42 Epoch: 7 target_val-Loss: 1.0567 target_val-Acc: 0.4513, Cost 0.5 sec
08-30 22:24:42 -----Epoch 8/49-----
08-30 22:24:42 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:24:46 Epoch: 8 source_train-Loss: 1.0621 source_train-Acc: 0.4434, Cost 3.7 sec
08-30 22:24:46 Epoch: 8 source_val-Loss: 1.0601 source_val-Acc: 0.4460, Cost 0.2 sec
08-30 22:24:46 Epoch: 8 target_val-Loss: 1.0553 target_val-Acc: 0.4502, Cost 0.4 sec
08-30 22:24:46 -----Epoch 9/49-----
08-30 22:24:46 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:24:49 Epoch: 9 source_train-Loss: 1.0608 source_train-Acc: 0.4456, Cost 3.1 sec
08-30 22:24:50 Epoch: 9 source_val-Loss: 1.0596 source_val-Acc: 0.4460, Cost 0.3 sec
08-30 22:24:50 Epoch: 9 target_val-Loss: 1.0533 target_val-Acc: 0.4507, Cost 0.4 sec
08-30 22:24:50 -----Epoch 10/49-----
08-30 22:24:50 current lr: [0.001, 0.001, 0.001]
08-30 22:24:52 Epoch: 10 [5120/7172], Train Loss: 0.8369 Train Acc: 0.5940,1896.0 examples/sec 0.07 sec/batch
Isc recall: 0
08-30 22:24:53 Epoch: 10 source_train-Loss: 1.0609 source_train-Acc: 0.4456, Cost 3.1 sec
08-30 22:24:53 Epoch: 10 source_val-Loss: 1.0605 source_val-Acc: 0.4456, Cost 0.2 sec
08-30 22:24:54 Epoch: 10 target_val-Loss: 1.0551 target_val-Acc: 0.4509, Cost 0.4 sec
08-30 22:24:54 -----Epoch 11/49-----
08-30 22:24:54 current lr: [0.001, 0.001, 0.001]
08-30 22:24:57 Epoch: 11 source_train-Loss: 1.0602 source_train-Acc: 0.4456, Cost 2.9 sec
08-30 22:24:57 Epoch: 11 source_val-Loss: 1.0598 source_val-Acc: 0.4456, Cost 0.3 sec
Isc recall: 0
08-30 22:24:57 Epoch: 11 target_val-Loss: 1.0541 target_val-Acc: 0.4511, Cost 0.4 sec
08-30 22:24:57 -----Epoch 12/49-----
08-30 22:24:57 current lr: [0.001, 0.001, 0.001]
08-30 22:25:01 Epoch: 12 source_train-Loss: 1.0603 source_train-Acc: 0.4460, Cost 3.5 sec
08-30 22:25:01 Epoch: 12 source_val-Loss: 1.0593 source_val-Acc: 0.4460, Cost 0.2 sec
Isc recall: 0
08-30 22:25:01 Epoch: 12 target_val-Loss: 1.0533 target_val-Acc: 0.4513, Cost 0.4 sec
08-30 22:25:01 -----Epoch 13/49-----
08-30 22:25:01 current lr: [0.001, 0.001, 0.001]
08-30 22:25:05 Epoch: 13 source_train-Loss: 1.0609 source_train-Acc: 0.4455, Cost 3.1 sec
08-30 22:25:05 Epoch: 13 source_val-Loss: 1.0596 source_val-Acc: 0.4460, Cost 0.2 sec
Isc recall: 0
08-30 22:25:05 Epoch: 13 target_val-Loss: 1.0537 target_val-Acc: 0.4498, Cost 0.4 sec
08-30 22:25:05 -----Epoch 14/49-----
08-30 22:25:05 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:25:08 Epoch: 14 source_train-Loss: 1.0601 source_train-Acc: 0.4457, Cost 3.0 sec
08-30 22:25:08 Epoch: 14 source_val-Loss: 1.0594 source_val-Acc: 0.4460, Cost 0.2 sec
08-30 22:25:09 Epoch: 14 target_val-Loss: 1.0533 target_val-Acc: 0.4500, Cost 0.4 sec
08-30 22:25:09 -----Epoch 15/49-----
08-30 22:25:09 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:25:12 Epoch: 15 source_train-Loss: 1.0599 source_train-Acc: 0.4457, Cost 3.1 sec
08-30 22:25:12 Epoch: 15 source_val-Loss: 1.0598 source_val-Acc: 0.4460, Cost 0.2 sec
08-30 22:25:12 Epoch: 15 target_val-Loss: 1.0546 target_val-Acc: 0.4511, Cost 0.4 sec
08-30 22:25:12 -----Epoch 16/49-----
08-30 22:25:12 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:25:16 Epoch: 16 source_train-Loss: 1.0609 source_train-Acc: 0.4457, Cost 3.1 sec
08-30 22:25:16 Epoch: 16 source_val-Loss: 1.0597 source_val-Acc: 0.4456, Cost 0.2 sec
08-30 22:25:16 Epoch: 16 target_val-Loss: 1.0537 target_val-Acc: 0.4511, Cost 0.4 sec
08-30 22:25:16 -----Epoch 17/49-----
08-30 22:25:16 current lr: [0.001, 0.001, 0.001]
Traceback (most recent call last):
  File "E:\Galaxy\yang7hi_battery\train_base.py", line 133, in <module>
    trainer.train(cond=condition)
  File "E:\Galaxy\yang7hi_battery\utlis\train_utils_base.py", line 538, in train
    loss.backward()
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\autograd\__init__.py", line 175, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt