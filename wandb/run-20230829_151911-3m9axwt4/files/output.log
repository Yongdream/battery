08-29 15:19:33 -----Epoch 0/127-----
08-29 15:19:33 current lr: [0.001, 0.001, 0.001, 0.001]
08-29 15:19:34 Epoch: 0 [0/14701], Train Loss: 1.6044 Train Acc: 0.1953,4.5 examples/sec 28.48 sec/batch
08-29 15:19:41 Epoch: 0 source_train-Loss: 1.2834 source_train-Acc: 0.3819, Cost 7.5 sec
08-29 15:19:41 Epoch: 0 source_val-Loss: 1.0515 source_val-Acc: 0.5014, Cost 0.4 sec
08-29 15:19:42 Epoch: 0 target_val-Loss: 1.5119 target_val-Acc: 0.3418, Cost 0.7 sec
08-29 15:19:42 -----Epoch 1/127-----
08-29 15:19:42 current lr: [0.001, 0.001, 0.001, 0.001]
Isc recall: 69.532
Traceback (most recent call last):
  File "E:\Galaxy\yang7hi_battery\train_base.py", line 124, in <module>
    trainer.train(cond=condition)
  File "E:\Galaxy\yang7hi_battery\utlis\train_utils_base.py", line 515, in train
    loss.backward()
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\autograd\__init__.py", line 175, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt