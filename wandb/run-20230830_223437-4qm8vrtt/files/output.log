08-30 22:34:45 method: DA
08-30 22:34:45 model_name: ALSTMAdFeatures
08-30 22:34:45 data_name: Battery
08-30 22:34:45 data_dir: ../processed
08-30 22:34:45 transfer_task: [[2], [0]]
08-30 22:34:45 normlizetype: mean-std
08-30 22:34:45 adabn: False
08-30 22:34:45 eval_all: False
08-30 22:34:45 adabn_epochs: 3
08-30 22:34:45 cuda_device: 0
08-30 22:34:45 checkpoint_dir: ./checkpoint
08-30 22:34:45 pretrained: False
08-30 22:34:45 batch_size: 128
08-30 22:34:45 num_workers: 0
08-30 22:34:45 seed: 3
08-30 22:34:45 patience: 50
08-30 22:34:45 bottleneck: True
08-30 22:34:45 bottleneck_num: 128
08-30 22:34:45 last_batch: False
08-30 22:34:45 distance_metric: True
08-30 22:34:45 distance_loss: JMMD
08-30 22:34:45 trade_off_distance: Step
08-30 22:34:45 lam_distance: 1.2
08-30 22:34:45 domain_adversarial: False
08-30 22:34:45 adversarial_loss: CDA
08-30 22:34:45 hidden_size: 1024
08-30 22:34:45 trade_off_adversarial: Step
08-30 22:34:45 lam_adversarial: 2
08-30 22:34:45 opt: adam
08-30 22:34:45 lr: 0.001
08-30 22:34:45 momentum: 0.9
08-30 22:34:45 weight_decay: 1e-05
08-30 22:34:45 lr_scheduler: step
08-30 22:34:45 gamma: 0.8
08-30 22:34:45 steps: 80, 95, 105
08-30 22:34:45 criterion: CeLoss
08-30 22:34:45 middle_epoch: 25
08-30 22:34:45 max_epoch: 50
08-30 22:34:45 print_step: 600
08-30 22:34:45 wandb: True
08-30 22:34:45 using 1 gpus

100%|██████████| 3/3 [00:04<00:00,  1.43s/it]


100%|██████████| 3/3 [00:04<00:00,  1.44s/it]
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [128, 3]                  --
├─ALSTMAdFeatures: 1-1                   [128, 128]                --
│    └─Sequential: 2-1                   [128, 60, 300]            --
│    │    └─Conv1d: 3-1                  [128, 32, 300]            2,720
│    │    └─ReLU: 3-2                    [128, 32, 300]            --
│    │    └─Conv1d: 3-3                  [128, 60, 300]            5,820
│    │    └─ReLU: 3-4                    [128, 60, 300]            --
│    └─GRU: 2-2                          [128, 300, 64]            124,800
│    └─GRU: 2-3                          [128, 300, 32]            27,072
│    └─Sequential: 2-4                   [128, 300, 1]             --
│    │    └─Linear: 3-5                  [128, 300, 16]            528
│    │    └─ReLU: 3-6                    [128, 300, 16]            --
│    │    └─Linear: 3-7                  [128, 300, 1]             16
│    │    └─Softmax: 3-8                 [128, 300, 1]             --
│    └─Linear: 2-5                       [128, 2048]               19,662,848
│    └─Linear: 2-6                       [128, 128]                262,272
├─Sequential: 1-2                        [128, 128]                --
│    └─Linear: 2-7                       [128, 128]                16,512
│    └─ReLU: 2-8                         [128, 128]                --
│    └─Dropout: 2-9                      [128, 128]                --
├─Linear: 1-3                            [128, 3]                  387
==========================================================================================
Total params: 20,102,975
Trainable params: 20,102,975
Non-trainable params: 0
Total mult-adds (G): 8.71
==========================================================================================
Input size (MB): 1.84
Forward/backward pass size (MB): 65.34
Params size (MB): 80.41
Estimated Total Size (MB): 147.59
==========================================================================================
Model build successfully!
08-30 22:34:58 ==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [128, 3]                  --
├─ALSTMAdFeatures: 1-1                   [128, 128]                --
│    └─Sequential: 2-1                   [128, 60, 300]            --
│    │    └─Conv1d: 3-1                  [128, 32, 300]            2,720
│    │    └─ReLU: 3-2                    [128, 32, 300]            --
│    │    └─Conv1d: 3-3                  [128, 60, 300]            5,820
│    │    └─ReLU: 3-4                    [128, 60, 300]            --
│    └─GRU: 2-2                          [128, 300, 64]            124,800
│    └─GRU: 2-3                          [128, 300, 32]            27,072
│    └─Sequential: 2-4                   [128, 300, 1]             --
│    │    └─Linear: 3-5                  [128, 300, 16]            528
│    │    └─ReLU: 3-6                    [128, 300, 16]            --
│    │    └─Linear: 3-7                  [128, 300, 1]             16
│    │    └─Softmax: 3-8                 [128, 300, 1]             --
│    └─Linear: 2-5                       [128, 2048]               19,662,848
│    └─Linear: 2-6                       [128, 128]                262,272
├─Sequential: 1-2                        [128, 128]                --
│    └─Linear: 2-7                       [128, 128]                16,512
│    └─ReLU: 2-8                         [128, 128]                --
│    └─Dropout: 2-9                      [128, 128]                --
├─Linear: 1-3                            [128, 3]                  387
==========================================================================================
Total params: 20,102,975
Trainable params: 20,102,975
Non-trainable params: 0
Total mult-adds (G): 8.71
==========================================================================================
Input size (MB): 1.84
Forward/backward pass size (MB): 65.34
Params size (MB): 80.41
Estimated Total Size (MB): 147.59
==========================================================================================
08-30 22:34:58 -----Epoch 0/49-----
08-30 22:34:58 current lr: [0.001, 0.001, 0.001]
08-30 22:34:58 Epoch: 0 [0/6568], Train Loss: 1.0866 Train Acc: 0.3828,158.5 examples/sec 0.81 sec/batch
08-30 22:35:01 Epoch: 0 source_train-Loss: 1.0768 source_train-Acc: 0.4531, Cost 3.4 sec
08-30 22:35:01 Epoch: 0 source_val-Loss: 1.0782 source_val-Acc: 0.3480, Cost 0.2 sec
Isc recall: 0
08-30 22:35:02 Epoch: 0 target_val-Loss: 1.0707 target_val-Acc: 0.3738, Cost 0.4 sec
08-30 22:35:02 -----Epoch 1/49-----
08-30 22:35:02 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:35:04 Epoch: 1 source_train-Loss: 0.8837 source_train-Acc: 0.5728, Cost 2.6 sec
08-30 22:35:04 Epoch: 1 source_val-Loss: 0.7829 source_val-Acc: 0.7379, Cost 0.2 sec
08-30 22:35:05 Epoch: 1 target_val-Loss: 0.8501 target_val-Acc: 0.6894, Cost 0.4 sec
08-30 22:35:05 -----Epoch 2/49-----
08-30 22:35:05 current lr: [0.001, 0.001, 0.001]
08-30 22:35:08 Epoch: 2 source_train-Loss: 0.5780 source_train-Acc: 0.7805, Cost 2.7 sec
Isc recall: 0
08-30 22:35:08 Epoch: 2 source_val-Loss: 0.5338 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:08 Epoch: 2 target_val-Loss: 0.6049 target_val-Acc: 0.8061, Cost 0.4 sec
08-30 22:35:08 -----Epoch 3/49-----
08-30 22:35:08 current lr: [0.001, 0.001, 0.001]
08-30 22:35:11 Epoch: 3 source_train-Loss: 0.5429 source_train-Acc: 0.7875, Cost 2.9 sec
08-30 22:35:11 Epoch: 3 source_val-Loss: 0.5328 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:12 Epoch: 3 target_val-Loss: 0.6232 target_val-Acc: 0.8063, Cost 0.4 sec
08-30 22:35:12 -----Epoch 4/49-----
08-30 22:35:12 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
Isc recall: 0
08-30 22:35:14 Epoch: 4 source_train-Loss: 0.5416 source_train-Acc: 0.7872, Cost 2.7 sec
08-30 22:35:15 Epoch: 4 source_val-Loss: 0.5329 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:15 Epoch: 4 target_val-Loss: 0.6199 target_val-Acc: 0.8065, Cost 0.4 sec
08-30 22:35:15 -----Epoch 5/49-----
08-30 22:35:15 current lr: [0.001, 0.001, 0.001]
08-30 22:35:18 Epoch: 5 source_train-Loss: 0.5410 source_train-Acc: 0.7868, Cost 2.6 sec
Isc recall: 0
08-30 22:35:18 Epoch: 5 source_val-Loss: 0.5329 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:18 Epoch: 5 target_val-Loss: 0.6225 target_val-Acc: 0.8051, Cost 0.4 sec
08-30 22:35:18 -----Epoch 6/49-----
08-30 22:35:18 current lr: [0.001, 0.001, 0.001]
08-30 22:35:21 Epoch: 6 source_train-Loss: 0.5410 source_train-Acc: 0.7872, Cost 2.8 sec
08-30 22:35:21 Epoch: 6 source_val-Loss: 0.5336 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:22 Epoch: 6 target_val-Loss: 0.6290 target_val-Acc: 0.8057, Cost 0.4 sec
08-30 22:35:22 -----Epoch 7/49-----
08-30 22:35:22 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
Isc recall: 0
08-30 22:35:24 Epoch: 7 source_train-Loss: 0.5410 source_train-Acc: 0.7871, Cost 2.6 sec
08-30 22:35:25 Epoch: 7 source_val-Loss: 0.5331 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:25 Epoch: 7 target_val-Loss: 0.6213 target_val-Acc: 0.8067, Cost 0.4 sec
08-30 22:35:25 -----Epoch 8/49-----
08-30 22:35:25 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:35:28 Epoch: 8 source_train-Loss: 0.5404 source_train-Acc: 0.7866, Cost 2.7 sec
08-30 22:35:28 Epoch: 8 source_val-Loss: 0.5332 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:28 Epoch: 8 target_val-Loss: 0.6193 target_val-Acc: 0.8065, Cost 0.4 sec
08-30 22:35:28 -----Epoch 9/49-----
08-30 22:35:28 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:35:31 Epoch: 9 source_train-Loss: 0.5402 source_train-Acc: 0.7871, Cost 2.7 sec
08-30 22:35:31 Epoch: 9 source_val-Loss: 0.5330 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:31 Epoch: 9 target_val-Loss: 0.6205 target_val-Acc: 0.8076, Cost 0.4 sec
08-30 22:35:31 -----Epoch 10/49-----
08-30 22:35:31 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:35:34 Epoch: 10 source_train-Loss: 0.5400 source_train-Acc: 0.7865, Cost 2.7 sec
08-30 22:35:34 Epoch: 10 source_val-Loss: 0.5337 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:35 Epoch: 10 target_val-Loss: 0.6266 target_val-Acc: 0.8061, Cost 0.4 sec
08-30 22:35:35 -----Epoch 11/49-----
08-30 22:35:35 current lr: [0.001, 0.001, 0.001]
08-30 22:35:37 Epoch: 11 [4992/6568], Train Loss: 0.6179 Train Acc: 0.7406,1993.3 examples/sec 0.06 sec/batch
08-30 22:35:37 Epoch: 11 source_train-Loss: 0.5396 source_train-Acc: 0.7869, Cost 2.7 sec
Isc recall: 0
08-30 22:35:38 Epoch: 11 source_val-Loss: 0.5337 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:38 Epoch: 11 target_val-Loss: 0.6200 target_val-Acc: 0.8063, Cost 0.4 sec
08-30 22:35:38 -----Epoch 12/49-----
08-30 22:35:38 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:35:41 Epoch: 12 source_train-Loss: 0.5396 source_train-Acc: 0.7866, Cost 2.7 sec
08-30 22:35:41 Epoch: 12 source_val-Loss: 0.5338 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:41 Epoch: 12 target_val-Loss: 0.6237 target_val-Acc: 0.8053, Cost 0.4 sec
08-30 22:35:41 -----Epoch 13/49-----
08-30 22:35:41 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:35:44 Epoch: 13 source_train-Loss: 0.5396 source_train-Acc: 0.7866, Cost 2.9 sec
08-30 22:35:45 Epoch: 13 source_val-Loss: 0.5331 source_val-Acc: 0.7869, Cost 0.3 sec
08-30 22:35:45 Epoch: 13 target_val-Loss: 0.6190 target_val-Acc: 0.8055, Cost 0.4 sec
08-30 22:35:45 -----Epoch 14/49-----
08-30 22:35:45 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:35:48 Epoch: 14 source_train-Loss: 0.5400 source_train-Acc: 0.7865, Cost 2.9 sec
08-30 22:35:48 Epoch: 14 source_val-Loss: 0.5335 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:35:49 Epoch: 14 target_val-Loss: 0.6172 target_val-Acc: 0.8055, Cost 0.4 sec
08-30 22:35:49 -----Epoch 15/49-----
08-30 22:35:49 current lr: [0.001, 0.001, 0.001]
08-30 22:35:52 Epoch: 15 source_train-Loss: 0.5393 source_train-Acc: 0.7866, Cost 3.0 sec
08-30 22:35:52 Epoch: 15 source_val-Loss: 0.5330 source_val-Acc: 0.7869, Cost 0.3 sec
Isc recall: 0
08-30 22:35:52 Epoch: 15 target_val-Loss: 0.6241 target_val-Acc: 0.8063, Cost 0.4 sec
08-30 22:35:52 -----Epoch 16/49-----
08-30 22:35:52 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:35:56 Epoch: 16 source_train-Loss: 0.5390 source_train-Acc: 0.7872, Cost 3.2 sec
08-30 22:35:56 Epoch: 16 source_val-Loss: 0.5328 source_val-Acc: 0.7869, Cost 0.3 sec
08-30 22:35:56 Epoch: 16 target_val-Loss: 0.6184 target_val-Acc: 0.8055, Cost 0.4 sec
08-30 22:35:56 -----Epoch 17/49-----
08-30 22:35:56 current lr: [0.001, 0.001, 0.001]
08-30 22:35:59 Epoch: 17 source_train-Loss: 0.5393 source_train-Acc: 0.7872, Cost 2.9 sec
08-30 22:35:59 Epoch: 17 source_val-Loss: 0.5335 source_val-Acc: 0.7869, Cost 0.2 sec
Isc recall: 0
08-30 22:36:00 Epoch: 17 target_val-Loss: 0.6110 target_val-Acc: 0.8065, Cost 0.4 sec
08-30 22:36:00 -----Epoch 18/49-----
08-30 22:36:00 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:36:03 Epoch: 18 source_train-Loss: 0.5386 source_train-Acc: 0.7878, Cost 2.9 sec
08-30 22:36:03 Epoch: 18 source_val-Loss: 0.5336 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:36:03 Epoch: 18 target_val-Loss: 0.6176 target_val-Acc: 0.8069, Cost 0.4 sec
08-30 22:36:03 -----Epoch 19/49-----
08-30 22:36:03 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:36:06 Epoch: 19 source_train-Loss: 0.5391 source_train-Acc: 0.7875, Cost 3.0 sec
08-30 22:36:06 Epoch: 19 source_val-Loss: 0.5346 source_val-Acc: 0.7869, Cost 0.3 sec
08-30 22:36:07 Epoch: 19 target_val-Loss: 0.6349 target_val-Acc: 0.8061, Cost 0.4 sec
08-30 22:36:07 -----Epoch 20/49-----
08-30 22:36:07 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:36:10 Epoch: 20 source_train-Loss: 0.5397 source_train-Acc: 0.7868, Cost 2.9 sec
08-30 22:36:10 Epoch: 20 source_val-Loss: 0.5330 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:36:11 Epoch: 20 target_val-Loss: 0.6239 target_val-Acc: 0.8057, Cost 0.4 sec
08-30 22:36:11 -----Epoch 21/49-----
08-30 22:36:11 current lr: [0.001, 0.001, 0.001]
08-30 22:36:14 Epoch: 21 source_train-Loss: 0.5392 source_train-Acc: 0.7875, Cost 3.0 sec
08-30 22:36:14 Epoch: 21 source_val-Loss: 0.5356 source_val-Acc: 0.7869, Cost 0.2 sec
Isc recall: 0
08-30 22:36:14 Epoch: 21 target_val-Loss: 0.6116 target_val-Acc: 0.8063, Cost 0.4 sec
08-30 22:36:14 -----Epoch 22/49-----
08-30 22:36:14 current lr: [0.001, 0.001, 0.001]
08-30 22:36:17 Epoch: 22 source_train-Loss: 0.5392 source_train-Acc: 0.7878, Cost 3.0 sec
08-30 22:36:17 Epoch: 22 source_val-Loss: 0.5338 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:36:18 Epoch: 22 target_val-Loss: 0.6298 target_val-Acc: 0.8061, Cost 0.4 sec
08-30 22:36:18 -----Epoch 23/49-----
08-30 22:36:18 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:36:20 Epoch: 23 [3456/6568], Train Loss: 0.5395 Train Acc: 0.7869,1801.9 examples/sec 0.07 sec/batch
Isc recall: 0
08-30 22:36:21 Epoch: 23 source_train-Loss: 0.5389 source_train-Acc: 0.7874, Cost 2.9 sec
08-30 22:36:21 Epoch: 23 source_val-Loss: 0.5327 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:36:21 Epoch: 23 target_val-Loss: 0.6198 target_val-Acc: 0.8065, Cost 0.4 sec
08-30 22:36:21 -----Epoch 24/49-----
08-30 22:36:21 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:36:25 Epoch: 24 source_train-Loss: 0.5389 source_train-Acc: 0.7865, Cost 3.2 sec
08-30 22:36:25 Epoch: 24 source_val-Loss: 0.5330 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:36:25 Epoch: 24 target_val-Loss: 0.6264 target_val-Acc: 0.8067, Cost 0.4 sec
08-30 22:36:25 -----Epoch 25/49-----
08-30 22:36:25 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:36:30 Epoch: 25 source_train-Loss: 1.0774 source_train-Acc: 0.7866, Cost 5.1 sec
08-30 22:36:31 Epoch: 25 source_val-Loss: 0.5334 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:36:31 Epoch: 25 target_val-Loss: 0.6253 target_val-Acc: 0.8057, Cost 0.4 sec
08-30 22:36:31 -----Epoch 26/49-----
08-30 22:36:31 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:36:36 Epoch: 26 source_train-Loss: 1.1032 source_train-Acc: 0.7865, Cost 4.9 sec
08-30 22:36:36 Epoch: 26 source_val-Loss: 0.5329 source_val-Acc: 0.7869, Cost 0.3 sec
08-30 22:36:37 Epoch: 26 target_val-Loss: 0.6184 target_val-Acc: 0.8063, Cost 0.4 sec
08-30 22:36:37 -----Epoch 27/49-----
08-30 22:36:37 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:36:41 Epoch: 27 source_train-Loss: 1.1265 source_train-Acc: 0.7866, Cost 4.2 sec
08-30 22:36:41 Epoch: 27 source_val-Loss: 0.5338 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:36:41 Epoch: 27 target_val-Loss: 0.6296 target_val-Acc: 0.8061, Cost 0.4 sec
08-30 22:36:41 -----Epoch 28/49-----
08-30 22:36:41 current lr: [0.001, 0.001, 0.001]
08-30 22:36:46 Epoch: 28 source_train-Loss: 1.1485 source_train-Acc: 0.7866, Cost 4.2 sec
08-30 22:36:46 Epoch: 28 source_val-Loss: 0.5331 source_val-Acc: 0.7869, Cost 0.2 sec
Isc recall: 0
08-30 22:36:46 Epoch: 28 target_val-Loss: 0.6128 target_val-Acc: 0.8065, Cost 0.4 sec
08-30 22:36:46 -----Epoch 29/49-----
08-30 22:36:46 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:36:51 Epoch: 29 source_train-Loss: 1.1618 source_train-Acc: 0.7865, Cost 4.7 sec
08-30 22:36:51 Epoch: 29 source_val-Loss: 0.5353 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:36:52 Epoch: 29 target_val-Loss: 0.6360 target_val-Acc: 0.8059, Cost 0.4 sec
08-30 22:36:52 -----Epoch 30/49-----
08-30 22:36:52 current lr: [0.001, 0.001, 0.001]
08-30 22:36:56 Epoch: 30 source_train-Loss: 1.1671 source_train-Acc: 0.7878, Cost 4.2 sec
08-30 22:36:56 Epoch: 30 source_val-Loss: 0.5339 source_val-Acc: 0.7869, Cost 0.2 sec
Isc recall: 0
08-30 22:36:56 Epoch: 30 target_val-Loss: 0.6344 target_val-Acc: 0.8059, Cost 0.4 sec
08-30 22:36:56 -----Epoch 31/49-----
08-30 22:36:56 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:37:01 Epoch: 31 source_train-Loss: 1.1803 source_train-Acc: 0.7868, Cost 4.3 sec
08-30 22:37:01 Epoch: 31 source_val-Loss: 0.5330 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:37:01 Epoch: 31 target_val-Loss: 0.6195 target_val-Acc: 0.8067, Cost 0.4 sec
08-30 22:37:01 -----Epoch 32/49-----
08-30 22:37:01 current lr: [0.001, 0.001, 0.001]
08-30 22:37:06 Epoch: 32 source_train-Loss: 1.1874 source_train-Acc: 0.7869, Cost 4.3 sec
Isc recall: 0
08-30 22:37:06 Epoch: 32 source_val-Loss: 0.5329 source_val-Acc: 0.7869, Cost 0.3 sec
08-30 22:37:06 Epoch: 32 target_val-Loss: 0.6214 target_val-Acc: 0.8057, Cost 0.4 sec
08-30 22:37:06 -----Epoch 33/49-----
08-30 22:37:06 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:37:11 Epoch: 33 source_train-Loss: 1.2041 source_train-Acc: 0.7872, Cost 4.5 sec
08-30 22:37:11 Epoch: 33 source_val-Loss: 0.5338 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:37:12 Epoch: 33 target_val-Loss: 0.6164 target_val-Acc: 0.8055, Cost 0.4 sec
08-30 22:37:12 -----Epoch 34/49-----
08-30 22:37:12 current lr: [0.001, 0.001, 0.001]
08-30 22:37:16 Epoch: 34 source_train-Loss: 1.1958 source_train-Acc: 0.7868, Cost 4.3 sec
08-30 22:37:16 Epoch: 34 source_val-Loss: 0.5369 source_val-Acc: 0.7869, Cost 0.2 sec
Isc recall: 0
08-30 22:37:17 Epoch: 34 target_val-Loss: 0.6175 target_val-Acc: 0.8065, Cost 0.4 sec
08-30 22:37:17 -----Epoch 35/49-----
08-30 22:37:17 current lr: [0.001, 0.001, 0.001]
08-30 22:37:18 Epoch: 35 [3840/6568], Train Loss: 1.0803 Train Acc: 0.7869,1314.8 examples/sec 0.10 sec/batch
Isc recall: 0
08-30 22:37:21 Epoch: 35 source_train-Loss: 1.1998 source_train-Acc: 0.7868, Cost 4.4 sec
08-30 22:37:21 Epoch: 35 source_val-Loss: 0.5393 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:37:22 Epoch: 35 target_val-Loss: 0.6191 target_val-Acc: 0.8063, Cost 0.4 sec
08-30 22:37:22 -----Epoch 36/49-----
08-30 22:37:22 current lr: [0.001, 0.001, 0.001]
08-30 22:37:26 Epoch: 36 source_train-Loss: 1.1993 source_train-Acc: 0.7874, Cost 4.3 sec
08-30 22:37:26 Epoch: 36 source_val-Loss: 0.5331 source_val-Acc: 0.7869, Cost 0.2 sec
Isc recall: 0
08-30 22:37:27 Epoch: 36 target_val-Loss: 0.6252 target_val-Acc: 0.8059, Cost 0.4 sec
08-30 22:37:27 -----Epoch 37/49-----
08-30 22:37:27 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:37:31 Epoch: 37 source_train-Loss: 1.1973 source_train-Acc: 0.7868, Cost 4.2 sec
08-30 22:37:31 Epoch: 37 source_val-Loss: 0.5331 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:37:31 Epoch: 37 target_val-Loss: 0.6257 target_val-Acc: 0.8061, Cost 0.4 sec
08-30 22:37:31 -----Epoch 38/49-----
08-30 22:37:31 current lr: [0.001, 0.001, 0.001]
08-30 22:37:36 Epoch: 38 source_train-Loss: 1.1983 source_train-Acc: 0.7871, Cost 4.6 sec
Isc recall: 0
08-30 22:37:36 Epoch: 38 source_val-Loss: 0.5337 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:37:37 Epoch: 38 target_val-Loss: 0.6202 target_val-Acc: 0.8055, Cost 0.4 sec
08-30 22:37:37 -----Epoch 39/49-----
08-30 22:37:37 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:37:41 Epoch: 39 source_train-Loss: 1.2088 source_train-Acc: 0.7875, Cost 4.3 sec
08-30 22:37:41 Epoch: 39 source_val-Loss: 0.5337 source_val-Acc: 0.7869, Cost 0.3 sec
08-30 22:37:42 Epoch: 39 target_val-Loss: 0.6178 target_val-Acc: 0.8065, Cost 0.4 sec
08-30 22:37:42 -----Epoch 40/49-----
08-30 22:37:42 current lr: [0.001, 0.001, 0.001]
08-30 22:37:46 Epoch: 40 source_train-Loss: 1.7346 source_train-Acc: 0.6317, Cost 4.6 sec
Isc recall: 0
08-30 22:37:46 Epoch: 40 source_val-Loss: 1.0642 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:37:47 Epoch: 40 target_val-Loss: 1.0538 target_val-Acc: 0.4502, Cost 0.4 sec
08-30 22:37:47 -----Epoch 41/49-----
08-30 22:37:47 current lr: [0.001, 0.001, 0.001]
Traceback (most recent call last):
  File "E:\Galaxy\yang7hi_battery\train_base.py", line 133, in <module>
    trainer.train(cond=condition)
  File "E:\Galaxy\yang7hi_battery\utlis\train_utils_base.py", line 538, in train
    loss.backward()
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\autograd\__init__.py", line 175, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: Function 'MulBackward0' returned nan values in its 1th output.