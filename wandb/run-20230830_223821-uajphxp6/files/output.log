08-30 22:38:28 method: DA
08-30 22:38:28 model_name: ALSTMAdFeatures
08-30 22:38:28 data_name: Battery
08-30 22:38:28 data_dir: ../processed
08-30 22:38:28 transfer_task: [[2], [0]]
08-30 22:38:28 normlizetype: mean-std
08-30 22:38:28 adabn: False
08-30 22:38:28 eval_all: False
08-30 22:38:28 adabn_epochs: 3
08-30 22:38:28 cuda_device: 0
08-30 22:38:28 checkpoint_dir: ./checkpoint
08-30 22:38:28 pretrained: False
08-30 22:38:28 batch_size: 128
08-30 22:38:28 num_workers: 0
08-30 22:38:28 seed: 31
08-30 22:38:28 patience: 50
08-30 22:38:28 bottleneck: True
08-30 22:38:28 bottleneck_num: 128
08-30 22:38:28 last_batch: False
08-30 22:38:28 distance_metric: True
08-30 22:38:28 distance_loss: JMMD
08-30 22:38:28 trade_off_distance: Step
08-30 22:38:28 lam_distance: 1.2
08-30 22:38:28 domain_adversarial: False
08-30 22:38:28 adversarial_loss: CDA
08-30 22:38:28 hidden_size: 1024
08-30 22:38:28 trade_off_adversarial: Step
08-30 22:38:28 lam_adversarial: 2
08-30 22:38:28 opt: adam
08-30 22:38:28 lr: 0.001
08-30 22:38:28 momentum: 0.9
08-30 22:38:28 weight_decay: 1e-05
08-30 22:38:28 lr_scheduler: step
08-30 22:38:28 gamma: 0.8
08-30 22:38:28 steps: 80, 95, 105
08-30 22:38:28 criterion: CeLoss
08-30 22:38:28 middle_epoch: 25
08-30 22:38:28 max_epoch: 50
08-30 22:38:28 print_step: 600
08-30 22:38:28 wandb: True
08-30 22:38:28 using 1 gpus

100%|██████████| 3/3 [00:04<00:00,  1.59s/it]


100%|██████████| 3/3 [00:04<00:00,  1.56s/it]
08-30 22:38:43 ==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [128, 3]                  --
├─ALSTMAdFeatures: 1-1                   [128, 128]                --
│    └─Sequential: 2-1                   [128, 60, 300]            --
│    │    └─Conv1d: 3-1                  [128, 32, 300]            2,720
│    │    └─ReLU: 3-2                    [128, 32, 300]            --
│    │    └─Conv1d: 3-3                  [128, 60, 300]            5,820
│    │    └─ReLU: 3-4                    [128, 60, 300]            --
│    └─GRU: 2-2                          [128, 300, 64]            124,800
│    └─GRU: 2-3                          [128, 300, 32]            27,072
│    └─Sequential: 2-4                   [128, 300, 1]             --
│    │    └─Linear: 3-5                  [128, 300, 16]            528
│    │    └─ReLU: 3-6                    [128, 300, 16]            --
│    │    └─Linear: 3-7                  [128, 300, 1]             16
│    │    └─Softmax: 3-8                 [128, 300, 1]             --
│    └─Linear: 2-5                       [128, 2048]               19,662,848
│    └─Linear: 2-6                       [128, 128]                262,272
├─Sequential: 1-2                        [128, 128]                --
│    └─Linear: 2-7                       [128, 128]                16,512
│    └─ReLU: 2-8                         [128, 128]                --
│    └─Dropout: 2-9                      [128, 128]                --
├─Linear: 1-3                            [128, 3]                  387
==========================================================================================
Total params: 20,102,975
Trainable params: 20,102,975
Non-trainable params: 0
Total mult-adds (G): 8.71
==========================================================================================
Input size (MB): 1.84
Forward/backward pass size (MB): 65.34
Params size (MB): 80.41
Estimated Total Size (MB): 147.59
==========================================================================================
08-30 22:38:43 -----Epoch 0/49-----
08-30 22:38:43 current lr: [0.001, 0.001, 0.001]
08-30 22:38:43 Epoch: 0 [0/6568], Train Loss: 1.1032 Train Acc: 0.2578,182.8 examples/sec 0.70 sec/batch
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [128, 3]                  --
├─ALSTMAdFeatures: 1-1                   [128, 128]                --
│    └─Sequential: 2-1                   [128, 60, 300]            --
│    │    └─Conv1d: 3-1                  [128, 32, 300]            2,720
│    │    └─ReLU: 3-2                    [128, 32, 300]            --
│    │    └─Conv1d: 3-3                  [128, 60, 300]            5,820
│    │    └─ReLU: 3-4                    [128, 60, 300]            --
│    └─GRU: 2-2                          [128, 300, 64]            124,800
│    └─GRU: 2-3                          [128, 300, 32]            27,072
│    └─Sequential: 2-4                   [128, 300, 1]             --
│    │    └─Linear: 3-5                  [128, 300, 16]            528
│    │    └─ReLU: 3-6                    [128, 300, 16]            --
│    │    └─Linear: 3-7                  [128, 300, 1]             16
│    │    └─Softmax: 3-8                 [128, 300, 1]             --
│    └─Linear: 2-5                       [128, 2048]               19,662,848
│    └─Linear: 2-6                       [128, 128]                262,272
├─Sequential: 1-2                        [128, 128]                --
│    └─Linear: 2-7                       [128, 128]                16,512
│    └─ReLU: 2-8                         [128, 128]                --
│    └─Dropout: 2-9                      [128, 128]                --
├─Linear: 1-3                            [128, 3]                  387
==========================================================================================
Total params: 20,102,975
Trainable params: 20,102,975
Non-trainable params: 0
Total mult-adds (G): 8.71
==========================================================================================
Input size (MB): 1.84
Forward/backward pass size (MB): 65.34
Params size (MB): 80.41
Estimated Total Size (MB): 147.59
==========================================================================================
Model build successfully!
08-30 22:38:46 Epoch: 0 source_train-Loss: 0.8781 source_train-Acc: 0.5869, Cost 3.6 sec
08-30 22:38:47 Epoch: 0 source_val-Loss: 0.6305 source_val-Acc: 0.7617, Cost 0.3 sec
08-30 22:38:47 Epoch: 0 target_val-Loss: 0.8186 target_val-Acc: 0.7420, Cost 0.4 sec
08-30 22:38:47 -----Epoch 1/49-----
08-30 22:38:47 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:38:50 Epoch: 1 source_train-Loss: 0.5598 source_train-Acc: 0.7788, Cost 3.1 sec
08-30 22:38:50 Epoch: 1 source_val-Loss: 0.5333 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:38:51 Epoch: 1 target_val-Loss: 0.6277 target_val-Acc: 0.8055, Cost 0.4 sec
08-30 22:38:51 -----Epoch 2/49-----
08-30 22:38:51 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:38:54 Epoch: 2 source_train-Loss: 0.5416 source_train-Acc: 0.7857, Cost 3.0 sec
08-30 22:38:54 Epoch: 2 source_val-Loss: 0.5329 source_val-Acc: 0.7869, Cost 0.3 sec
08-30 22:38:55 Epoch: 2 target_val-Loss: 0.6263 target_val-Acc: 0.8057, Cost 0.4 sec
08-30 22:38:55 -----Epoch 3/49-----
08-30 22:38:55 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:38:57 Epoch: 3 source_train-Loss: 0.5414 source_train-Acc: 0.7865, Cost 2.8 sec
08-30 22:38:58 Epoch: 3 source_val-Loss: 0.5340 source_val-Acc: 0.7869, Cost 0.3 sec
08-30 22:38:58 Epoch: 3 target_val-Loss: 0.6314 target_val-Acc: 0.8065, Cost 0.4 sec
08-30 22:38:58 -----Epoch 4/49-----
08-30 22:38:58 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:39:01 Epoch: 4 source_train-Loss: 0.5401 source_train-Acc: 0.7863, Cost 2.9 sec
08-30 22:39:01 Epoch: 4 source_val-Loss: 0.5366 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:39:02 Epoch: 4 target_val-Loss: 0.6332 target_val-Acc: 0.8061, Cost 0.4 sec
08-30 22:39:02 -----Epoch 5/49-----
08-30 22:39:02 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:39:04 Epoch: 5 source_train-Loss: 0.5392 source_train-Acc: 0.7868, Cost 2.8 sec
08-30 22:39:04 Epoch: 5 source_val-Loss: 0.5353 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:39:05 Epoch: 5 target_val-Loss: 0.6386 target_val-Acc: 0.8059, Cost 0.4 sec
08-30 22:39:05 -----Epoch 6/49-----
08-30 22:39:05 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:39:08 Epoch: 6 source_train-Loss: 0.5389 source_train-Acc: 0.7871, Cost 3.0 sec
08-30 22:39:08 Epoch: 6 source_val-Loss: 0.5339 source_val-Acc: 0.7869, Cost 0.2 sec
Isc recall: 0
08-30 22:39:09 Epoch: 6 target_val-Loss: 0.6118 target_val-Acc: 0.8067, Cost 0.4 sec
08-30 22:39:09 -----Epoch 7/49-----
08-30 22:39:09 current lr: [0.001, 0.001, 0.001]
08-30 22:39:11 Epoch: 7 source_train-Loss: 0.5374 source_train-Acc: 0.7863, Cost 2.8 sec
08-30 22:39:12 Epoch: 7 source_val-Loss: 0.5231 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:39:12 Epoch: 7 target_val-Loss: 0.6249 target_val-Acc: 0.8057, Cost 0.4 sec
08-30 22:39:12 -----Epoch 8/49-----
08-30 22:39:12 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:39:15 Epoch: 8 source_train-Loss: 0.5292 source_train-Acc: 0.8033, Cost 2.9 sec
08-30 22:39:15 Epoch: 8 source_val-Loss: 1.9594 source_val-Acc: 0.3612, Cost 0.2 sec
08-30 22:39:16 Epoch: 8 target_val-Loss: 1.0263 target_val-Acc: 0.6012, Cost 0.4 sec
08-30 22:39:16 -----Epoch 9/49-----
08-30 22:39:16 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:39:18 Epoch: 9 source_train-Loss: 0.6380 source_train-Acc: 0.7365, Cost 2.8 sec
08-30 22:39:19 Epoch: 9 source_val-Loss: 0.5337 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:39:19 Epoch: 9 target_val-Loss: 0.6177 target_val-Acc: 0.8061, Cost 0.4 sec
08-30 22:39:19 -----Epoch 10/49-----
08-30 22:39:19 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:39:22 Epoch: 10 source_train-Loss: 0.5383 source_train-Acc: 0.7866, Cost 2.8 sec
08-30 22:39:22 Epoch: 10 source_val-Loss: 0.5278 source_val-Acc: 0.7869, Cost 0.2 sec
Isc recall: 0
08-30 22:39:22 Epoch: 10 target_val-Loss: 0.6355 target_val-Acc: 0.8063, Cost 0.4 sec
08-30 22:39:22 -----Epoch 11/49-----
08-30 22:39:22 current lr: [0.001, 0.001, 0.001]
08-30 22:39:25 Epoch: 11 [4992/6568], Train Loss: 0.5740 Train Acc: 0.7695,1865.8 examples/sec 0.07 sec/batch
08-30 22:39:25 Epoch: 11 source_train-Loss: 0.4989 source_train-Acc: 0.8306, Cost 2.8 sec
08-30 22:39:25 Epoch: 11 source_val-Loss: 0.4329 source_val-Acc: 0.8807, Cost 0.2 sec
08-30 22:39:26 Epoch: 11 target_val-Loss: 0.7242 target_val-Acc: 0.6957, Cost 0.4 sec
08-30 22:39:26 -----Epoch 12/49-----
08-30 22:39:26 current lr: [0.001, 0.001, 0.001]
Isc recall: 40.91
08-30 22:39:29 Epoch: 12 source_train-Loss: 0.5285 source_train-Acc: 0.8081, Cost 2.7 sec
08-30 22:39:29 Epoch: 12 source_val-Loss: 0.5145 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:39:29 Epoch: 12 target_val-Loss: 0.6181 target_val-Acc: 0.8063, Cost 0.4 sec
08-30 22:39:29 -----Epoch 13/49-----
08-30 22:39:29 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:39:32 Epoch: 13 source_train-Loss: 0.4990 source_train-Acc: 0.8318, Cost 2.8 sec
08-30 22:39:32 Epoch: 13 source_val-Loss: 0.4316 source_val-Acc: 0.9091, Cost 0.2 sec
08-30 22:39:33 Epoch: 13 target_val-Loss: 0.7345 target_val-Acc: 0.7105, Cost 0.4 sec
08-30 22:39:33 -----Epoch 14/49-----
08-30 22:39:33 current lr: [0.001, 0.001, 0.001]
Isc recall: 37.53757575757576
08-30 22:39:35 Epoch: 14 source_train-Loss: 0.6747 source_train-Acc: 0.7315, Cost 2.7 sec
08-30 22:39:36 Epoch: 14 source_val-Loss: 0.5431 source_val-Acc: 0.7869, Cost 0.2 sec
08-30 22:39:36 Epoch: 14 target_val-Loss: 0.6732 target_val-Acc: 0.8065, Cost 0.4 sec
08-30 22:39:36 -----Epoch 15/49-----
08-30 22:39:36 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:39:39 Epoch: 15 source_train-Loss: 0.6201 source_train-Acc: 0.7770, Cost 2.7 sec
08-30 22:39:39 Epoch: 15 source_val-Loss: 0.5636 source_val-Acc: 0.7752, Cost 0.2 sec
08-30 22:39:39 Epoch: 15 target_val-Loss: 0.6762 target_val-Acc: 0.7868, Cost 0.4 sec
08-30 22:39:39 -----Epoch 16/49-----
08-30 22:39:39 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:39:42 Epoch: 16 source_train-Loss: 0.5402 source_train-Acc: 0.7892, Cost 2.8 sec
08-30 22:39:42 Epoch: 16 source_val-Loss: 0.5075 source_val-Acc: 0.8164, Cost 0.3 sec
Isc recall: 0.4852380952380952
08-30 22:39:43 Epoch: 16 target_val-Loss: 0.6203 target_val-Acc: 0.8004, Cost 0.4 sec
08-30 22:39:43 -----Epoch 17/49-----
08-30 22:39:43 current lr: [0.001, 0.001, 0.001]
08-30 22:39:46 Epoch: 17 source_train-Loss: 0.4623 source_train-Acc: 0.8735, Cost 2.9 sec
08-30 22:39:46 Epoch: 17 source_val-Loss: 0.5243 source_val-Acc: 0.8235, Cost 0.2 sec
08-30 22:39:46 Epoch: 17 target_val-Loss: 0.6875 target_val-Acc: 0.7387, Cost 0.4 sec
08-30 22:39:46 -----Epoch 18/49-----
08-30 22:39:46 current lr: [0.001, 0.001, 0.001]
Isc recall: 22.73
08-30 22:39:49 Epoch: 18 source_train-Loss: 0.4624 source_train-Acc: 0.8739, Cost 2.7 sec
08-30 22:39:49 Epoch: 18 source_val-Loss: 0.4324 source_val-Acc: 0.8928, Cost 0.2 sec
08-30 22:39:50 Epoch: 18 target_val-Loss: 0.8032 target_val-Acc: 0.7190, Cost 0.4 sec
08-30 22:39:50 -----Epoch 19/49-----
08-30 22:39:50 current lr: [0.001, 0.001, 0.001]
Isc recall: 26.514054054054053
08-30 22:39:52 Epoch: 19 source_train-Loss: 0.4446 source_train-Acc: 0.8840, Cost 2.8 sec
08-30 22:39:53 Epoch: 19 source_val-Loss: 0.4545 source_val-Acc: 0.8658, Cost 0.2 sec
08-30 22:39:53 Epoch: 19 target_val-Loss: 0.8289 target_val-Acc: 0.6774, Cost 0.4 sec
08-30 22:39:53 -----Epoch 20/49-----
08-30 22:39:53 current lr: [0.001, 0.001, 0.001]
Isc recall: 36.0
08-30 22:39:56 Epoch: 20 source_train-Loss: 0.4517 source_train-Acc: 0.8824, Cost 2.7 sec
08-30 22:39:56 Epoch: 20 source_val-Loss: 0.4292 source_val-Acc: 0.8995, Cost 0.2 sec
08-30 22:39:56 Epoch: 20 target_val-Loss: 0.7704 target_val-Acc: 0.7019, Cost 0.4 sec
08-30 22:39:56 -----Epoch 21/49-----
08-30 22:39:56 current lr: [0.001, 0.001, 0.001]
Isc recall: 35.62375000000001
08-30 22:39:59 Epoch: 21 source_train-Loss: 0.4380 source_train-Acc: 0.8963, Cost 2.8 sec
08-30 22:39:59 Epoch: 21 source_val-Loss: 0.4256 source_val-Acc: 0.8974, Cost 0.2 sec
08-30 22:40:00 Epoch: 21 target_val-Loss: 0.7613 target_val-Acc: 0.7200, Cost 0.4 sec
08-30 22:40:00 -----Epoch 22/49-----
08-30 22:40:00 current lr: [0.001, 0.001, 0.001]
Isc recall: 43.48
08-30 22:40:03 Epoch: 22 source_train-Loss: 0.4525 source_train-Acc: 0.8819, Cost 2.9 sec
08-30 22:40:03 Epoch: 22 source_val-Loss: 0.4644 source_val-Acc: 0.8601, Cost 0.2 sec
08-30 22:40:03 Epoch: 22 target_val-Loss: 0.7439 target_val-Acc: 0.7161, Cost 0.4 sec
08-30 22:40:03 -----Epoch 23/49-----
08-30 22:40:03 current lr: [0.001, 0.001, 0.001]
Isc recall: 39.739999999999995
08-30 22:40:05 Epoch: 23 [3456/6568], Train Loss: 0.5042 Train Acc: 0.8408,1895.6 examples/sec 0.07 sec/batch
08-30 22:40:07 Epoch: 23 source_train-Loss: 0.4445 source_train-Acc: 0.8871, Cost 3.7 sec
08-30 22:40:07 Epoch: 23 source_val-Loss: 0.4422 source_val-Acc: 0.8704, Cost 0.2 sec
08-30 22:40:08 Epoch: 23 target_val-Loss: 0.8129 target_val-Acc: 0.6861, Cost 0.4 sec
08-30 22:40:08 -----Epoch 24/49-----
08-30 22:40:08 current lr: [0.001, 0.001, 0.001]
Isc recall: 27.27
08-30 22:40:11 Epoch: 24 source_train-Loss: 0.4496 source_train-Acc: 0.8808, Cost 2.9 sec
08-30 22:40:11 Epoch: 24 source_val-Loss: 0.4112 source_val-Acc: 0.9077, Cost 0.2 sec
08-30 22:40:11 Epoch: 24 target_val-Loss: 0.8224 target_val-Acc: 0.6988, Cost 0.4 sec
08-30 22:40:11 -----Epoch 25/49-----
08-30 22:40:11 current lr: [0.001, 0.001, 0.001]
Isc recall: 30.573636363636364
08-30 22:40:16 Epoch: 25 source_train-Loss: 0.8768 source_train-Acc: 0.8915, Cost 4.6 sec
08-30 22:40:16 Epoch: 25 source_val-Loss: 0.4149 source_val-Acc: 0.9091, Cost 0.2 sec
08-30 22:40:16 Epoch: 25 target_val-Loss: 0.7138 target_val-Acc: 0.7132, Cost 0.4 sec
08-30 22:40:16 -----Epoch 26/49-----
08-30 22:40:16 current lr: [0.001, 0.001, 0.001]
Isc recall: 28.2925
08-30 22:40:21 Epoch: 26 source_train-Loss: 0.8861 source_train-Acc: 0.8986, Cost 4.6 sec
08-30 22:40:21 Epoch: 26 source_val-Loss: 0.4096 source_val-Acc: 0.9126, Cost 0.2 sec
08-30 22:40:22 Epoch: 26 target_val-Loss: 0.8208 target_val-Acc: 0.7021, Cost 0.4 sec
08-30 22:40:22 -----Epoch 27/49-----
08-30 22:40:22 current lr: [0.001, 0.001, 0.001]
Isc recall: 26.577142857142857
08-30 22:40:26 Epoch: 27 source_train-Loss: 0.9080 source_train-Acc: 0.8992, Cost 4.5 sec
08-30 22:40:26 Epoch: 27 source_val-Loss: 0.4547 source_val-Acc: 0.8636, Cost 0.2 sec
08-30 22:40:27 Epoch: 27 target_val-Loss: 0.7882 target_val-Acc: 0.6865, Cost 0.5 sec
08-30 22:40:27 -----Epoch 28/49-----
08-30 22:40:27 current lr: [0.001, 0.001, 0.001]
Isc recall: 20.098000000000003
08-30 22:40:32 Epoch: 28 source_train-Loss: 1.0149 source_train-Acc: 0.8649, Cost 4.7 sec
08-30 22:40:32 Epoch: 28 source_val-Loss: 0.4138 source_val-Acc: 0.9112, Cost 0.2 sec
08-30 22:40:32 Epoch: 28 target_val-Loss: 0.7412 target_val-Acc: 0.7185, Cost 0.4 sec
08-30 22:40:32 -----Epoch 29/49-----
08-30 22:40:32 current lr: [0.001, 0.001, 0.001]
Isc recall: 28.85478260869565
08-30 22:40:37 Epoch: 29 source_train-Loss: 0.9433 source_train-Acc: 0.8998, Cost 4.4 sec
08-30 22:40:37 Epoch: 29 source_val-Loss: 0.4166 source_val-Acc: 0.9023, Cost 0.2 sec
08-30 22:40:37 Epoch: 29 target_val-Loss: 0.7527 target_val-Acc: 0.7093, Cost 0.4 sec
08-30 22:40:37 -----Epoch 30/49-----
08-30 22:40:37 current lr: [0.001, 0.001, 0.001]
Isc recall: 26.47
08-30 22:40:42 Epoch: 30 source_train-Loss: 0.9922 source_train-Acc: 0.8813, Cost 4.6 sec
08-30 22:40:42 Epoch: 30 source_val-Loss: 0.4123 source_val-Acc: 0.9148, Cost 0.2 sec
08-30 22:40:43 Epoch: 30 target_val-Loss: 0.7814 target_val-Acc: 0.7037, Cost 0.4 sec
08-30 22:40:43 -----Epoch 31/49-----
08-30 22:40:43 current lr: [0.001, 0.001, 0.001]
Isc recall: 35.44
08-30 22:40:47 Epoch: 31 source_train-Loss: 0.9958 source_train-Acc: 0.8892, Cost 4.2 sec
08-30 22:40:47 Epoch: 31 source_val-Loss: 0.4238 source_val-Acc: 0.9009, Cost 0.2 sec
08-30 22:40:47 Epoch: 31 target_val-Loss: 0.7116 target_val-Acc: 0.7204, Cost 0.4 sec
08-30 22:40:47 -----Epoch 32/49-----
08-30 22:40:47 current lr: [0.001, 0.001, 0.001]
Isc recall: 33.06111111111111
08-30 22:40:52 Epoch: 32 source_train-Loss: 1.0031 source_train-Acc: 0.8856, Cost 4.5 sec
08-30 22:40:52 Epoch: 32 source_val-Loss: 0.4625 source_val-Acc: 0.8594, Cost 0.2 sec
08-30 22:40:52 Epoch: 32 target_val-Loss: 0.7823 target_val-Acc: 0.7185, Cost 0.4 sec
08-30 22:40:52 -----Epoch 33/49-----
08-30 22:40:52 current lr: [0.001, 0.001, 0.001]
Isc recall: 38.45538461538462
08-30 22:40:57 Epoch: 33 source_train-Loss: 1.0482 source_train-Acc: 0.8629, Cost 4.2 sec
08-30 22:40:57 Epoch: 33 source_val-Loss: 0.4299 source_val-Acc: 0.8999, Cost 0.2 sec
08-30 22:40:57 Epoch: 33 target_val-Loss: 0.7769 target_val-Acc: 0.7068, Cost 0.4 sec
08-30 22:40:57 -----Epoch 34/49-----
08-30 22:40:57 current lr: [0.001, 0.001, 0.001]
Isc recall: 19.007419354838706
08-30 22:41:02 Epoch: 34 source_train-Loss: 1.0193 source_train-Acc: 0.8877, Cost 4.4 sec
08-30 22:41:02 Epoch: 34 source_val-Loss: 0.4310 source_val-Acc: 0.8892, Cost 0.3 sec
08-30 22:41:02 Epoch: 34 target_val-Loss: 0.6938 target_val-Acc: 0.7142, Cost 0.4 sec
08-30 22:41:02 -----Epoch 35/49-----
08-30 22:41:02 current lr: [0.001, 0.001, 0.001]
Isc recall: 20.69
08-30 22:41:04 Epoch: 35 [3840/6568], Train Loss: 0.9039 Train Acc: 0.8868,1311.2 examples/sec 0.10 sec/batch
08-30 22:41:07 Epoch: 35 source_train-Loss: 1.0048 source_train-Acc: 0.8961, Cost 4.4 sec
08-30 22:41:07 Epoch: 35 source_val-Loss: 0.4044 source_val-Acc: 0.9183, Cost 0.2 sec
08-30 22:41:07 Epoch: 35 target_val-Loss: 0.7442 target_val-Acc: 0.7060, Cost 0.4 sec
08-30 22:41:07 -----Epoch 36/49-----
08-30 22:41:07 current lr: [0.001, 0.001, 0.001]
Isc recall: 27.777500000000003
08-30 22:41:12 Epoch: 36 source_train-Loss: 0.9881 source_train-Acc: 0.8980, Cost 4.4 sec
08-30 22:41:12 Epoch: 36 source_val-Loss: 0.4517 source_val-Acc: 0.8707, Cost 0.3 sec
08-30 22:41:12 Epoch: 36 target_val-Loss: 0.7091 target_val-Acc: 0.6998, Cost 0.4 sec
08-30 22:41:12 -----Epoch 37/49-----
08-30 22:41:12 current lr: [0.001, 0.001, 0.001]
Isc recall: 28.0
08-30 22:41:17 Epoch: 37 source_train-Loss: 1.0021 source_train-Acc: 0.8883, Cost 4.3 sec
08-30 22:41:17 Epoch: 37 source_val-Loss: 0.4395 source_val-Acc: 0.8928, Cost 0.2 sec
08-30 22:41:17 Epoch: 37 target_val-Loss: 0.6520 target_val-Acc: 0.7303, Cost 0.4 sec
08-30 22:41:17 -----Epoch 38/49-----
08-30 22:41:17 current lr: [0.001, 0.001, 0.001]
Isc recall: 37.93
08-30 22:41:22 Epoch: 38 source_train-Loss: 1.0512 source_train-Acc: 0.8744, Cost 4.4 sec
08-30 22:41:22 Epoch: 38 source_val-Loss: 0.4085 source_val-Acc: 0.9183, Cost 0.3 sec
08-30 22:41:22 Epoch: 38 target_val-Loss: 0.7441 target_val-Acc: 0.7111, Cost 0.4 sec
08-30 22:41:22 -----Epoch 39/49-----
08-30 22:41:22 current lr: [0.001, 0.001, 0.001]
Isc recall: 30.87192307692307
08-30 22:41:27 Epoch: 39 source_train-Loss: 1.0222 source_train-Acc: 0.8840, Cost 4.4 sec
08-30 22:41:27 Epoch: 39 source_val-Loss: 0.4162 source_val-Acc: 0.9148, Cost 0.2 sec
08-30 22:41:28 Epoch: 39 target_val-Loss: 0.7076 target_val-Acc: 0.7177, Cost 0.4 sec
08-30 22:41:28 -----Epoch 40/49-----
08-30 22:41:28 current lr: [0.001, 0.001, 0.001]
Isc recall: 26.02
08-30 22:41:32 Epoch: 40 source_train-Loss: 1.0403 source_train-Acc: 0.8771, Cost 4.3 sec
08-30 22:41:32 Epoch: 40 source_val-Loss: 0.4211 source_val-Acc: 0.9020, Cost 0.3 sec
08-30 22:41:33 Epoch: 40 target_val-Loss: 0.7108 target_val-Acc: 0.7301, Cost 0.4 sec
08-30 22:41:33 -----Epoch 41/49-----
08-30 22:41:33 current lr: [0.001, 0.001, 0.001]
Isc recall: 23.364285714285717
Traceback (most recent call last):
  File "E:\Galaxy\yang7hi_battery\train_base.py", line 133, in <module>
    trainer.train(cond=condition)
  File "E:\Galaxy\yang7hi_battery\utlis\train_utils_base.py", line 538, in train
    loss.backward()
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\autograd\__init__.py", line 175, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt