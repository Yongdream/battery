08-30 22:31:25 method: DA
08-30 22:31:25 model_name: ALSTMAdFeatures
08-30 22:31:25 data_name: Battery
08-30 22:31:25 data_dir: ../processed
08-30 22:31:25 transfer_task: [[2], [0]]
08-30 22:31:25 normlizetype: mean-std
08-30 22:31:25 adabn: False
08-30 22:31:25 eval_all: False
08-30 22:31:25 adabn_epochs: 3
08-30 22:31:25 cuda_device: 0
08-30 22:31:25 checkpoint_dir: ./checkpoint
08-30 22:31:25 pretrained: False
08-30 22:31:25 batch_size: 128
08-30 22:31:25 num_workers: 0
08-30 22:31:25 seed: 3
08-30 22:31:25 patience: 50
08-30 22:31:25 bottleneck: True
08-30 22:31:25 bottleneck_num: 128
08-30 22:31:25 last_batch: False
08-30 22:31:25 distance_metric: True
08-30 22:31:25 distance_loss: JMMD
08-30 22:31:25 trade_off_distance: Step
08-30 22:31:25 lam_distance: 1.2
08-30 22:31:25 domain_adversarial: False
08-30 22:31:25 adversarial_loss: CDA
08-30 22:31:25 hidden_size: 1024
08-30 22:31:25 trade_off_adversarial: Step
08-30 22:31:25 lam_adversarial: 2
08-30 22:31:25 opt: adam
08-30 22:31:25 lr: 0.001
08-30 22:31:25 momentum: 0.9
08-30 22:31:25 weight_decay: 1e-05
08-30 22:31:25 lr_scheduler: step
08-30 22:31:25 gamma: 0.8
08-30 22:31:25 steps: 80, 95, 105
08-30 22:31:25 criterion: CeLoss
08-30 22:31:25 middle_epoch: 25
08-30 22:31:25 max_epoch: 50
08-30 22:31:25 print_step: 600
08-30 22:31:25 wandb: True
08-30 22:31:25 using 1 gpus

100%|██████████| 3/3 [00:04<00:00,  1.52s/it]


100%|██████████| 3/3 [00:04<00:00,  1.36s/it]
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [128, 3]                  --
├─ALSTMAdFeatures: 1-1                   [128, 128]                --
│    └─Sequential: 2-1                   [128, 60, 300]            --
│    │    └─Conv1d: 3-1                  [128, 32, 300]            2,720
│    │    └─ReLU: 3-2                    [128, 32, 300]            --
│    │    └─Conv1d: 3-3                  [128, 60, 300]            5,820
│    │    └─ReLU: 3-4                    [128, 60, 300]            --
│    └─GRU: 2-2                          [128, 300, 64]            124,800
│    └─GRU: 2-3                          [128, 300, 32]            27,072
│    └─Sequential: 2-4                   [128, 300, 1]             --
│    │    └─Linear: 3-5                  [128, 300, 16]            528
│    │    └─ReLU: 3-6                    [128, 300, 16]            --
│    │    └─Linear: 3-7                  [128, 300, 1]             16
│    │    └─Softmax: 3-8                 [128, 300, 1]             --
│    └─Linear: 2-5                       [128, 2048]               19,662,848
│    └─Linear: 2-6                       [128, 128]                262,272
├─Sequential: 1-2                        [128, 128]                --
│    └─Linear: 2-7                       [128, 128]                16,512
│    └─ReLU: 2-8                         [128, 128]                --
│    └─Dropout: 2-9                      [128, 128]                --
├─Linear: 1-3                            [128, 3]                  387
==========================================================================================
Total params: 20,102,975
Trainable params: 20,102,975
Non-trainable params: 0
Total mult-adds (G): 8.71
==========================================================================================
Input size (MB): 1.84
Forward/backward pass size (MB): 65.34
Params size (MB): 80.41
Estimated Total Size (MB): 147.59
==========================================================================================
Model build successfully!
08-30 22:31:40 ==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [128, 3]                  --
├─ALSTMAdFeatures: 1-1                   [128, 128]                --
│    └─Sequential: 2-1                   [128, 60, 300]            --
│    │    └─Conv1d: 3-1                  [128, 32, 300]            2,720
│    │    └─ReLU: 3-2                    [128, 32, 300]            --
│    │    └─Conv1d: 3-3                  [128, 60, 300]            5,820
│    │    └─ReLU: 3-4                    [128, 60, 300]            --
│    └─GRU: 2-2                          [128, 300, 64]            124,800
│    └─GRU: 2-3                          [128, 300, 32]            27,072
│    └─Sequential: 2-4                   [128, 300, 1]             --
│    │    └─Linear: 3-5                  [128, 300, 16]            528
│    │    └─ReLU: 3-6                    [128, 300, 16]            --
│    │    └─Linear: 3-7                  [128, 300, 1]             16
│    │    └─Softmax: 3-8                 [128, 300, 1]             --
│    └─Linear: 2-5                       [128, 2048]               19,662,848
│    └─Linear: 2-6                       [128, 128]                262,272
├─Sequential: 1-2                        [128, 128]                --
│    └─Linear: 2-7                       [128, 128]                16,512
│    └─ReLU: 2-8                         [128, 128]                --
│    └─Dropout: 2-9                      [128, 128]                --
├─Linear: 1-3                            [128, 3]                  387
==========================================================================================
Total params: 20,102,975
Trainable params: 20,102,975
Non-trainable params: 0
Total mult-adds (G): 8.71
==========================================================================================
Input size (MB): 1.84
Forward/backward pass size (MB): 65.34
Params size (MB): 80.41
Estimated Total Size (MB): 147.59
==========================================================================================
08-30 22:31:40 -----Epoch 0/49-----
08-30 22:31:40 current lr: [0.001, 0.001, 0.001]
08-30 22:31:41 Epoch: 0 [0/6568], Train Loss: 1.0866 Train Acc: 0.3828,131.4 examples/sec 0.97 sec/batch
08-30 22:31:43 Epoch: 0 source_train-Loss: 1.0769 source_train-Acc: 0.4530, Cost 3.7 sec
Isc recall: 0
08-30 22:31:44 Epoch: 0 source_val-Loss: 1.0784 source_val-Acc: 0.3480, Cost 0.2 sec
08-30 22:31:44 Epoch: 0 target_val-Loss: 1.0712 target_val-Acc: 0.3731, Cost 0.4 sec
08-30 22:31:44 -----Epoch 1/49-----
08-30 22:31:44 current lr: [0.001, 0.001, 0.001]
08-30 22:31:47 Epoch: 1 source_train-Loss: 1.0422 source_train-Acc: 0.4072, Cost 2.8 sec
08-30 22:31:47 Epoch: 1 source_val-Loss: 1.0645 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:31:47 Epoch: 1 target_val-Loss: 1.0534 target_val-Acc: 0.4496, Cost 0.4 sec
08-30 22:31:47 -----Epoch 2/49-----
08-30 22:31:47 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
Isc recall: 0
08-30 22:31:50 Epoch: 2 source_train-Loss: 1.0668 source_train-Acc: 0.4380, Cost 2.8 sec
08-30 22:31:50 Epoch: 2 source_val-Loss: 1.0676 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:31:51 Epoch: 2 target_val-Loss: 1.0608 target_val-Acc: 0.4500, Cost 0.4 sec
08-30 22:31:51 -----Epoch 3/49-----
08-30 22:31:51 current lr: [0.001, 0.001, 0.001]
08-30 22:31:54 Epoch: 3 source_train-Loss: 1.0674 source_train-Acc: 0.4363, Cost 2.8 sec
Isc recall: 0
08-30 22:31:54 Epoch: 3 source_val-Loss: 1.0651 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:31:54 Epoch: 3 target_val-Loss: 1.0557 target_val-Acc: 0.4511, Cost 0.4 sec
08-30 22:31:54 -----Epoch 4/49-----
08-30 22:31:54 current lr: [0.001, 0.001, 0.001]
08-30 22:31:57 Epoch: 4 source_train-Loss: 1.0664 source_train-Acc: 0.4390, Cost 2.8 sec
08-30 22:31:57 Epoch: 4 source_val-Loss: 1.0670 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:31:58 Epoch: 4 target_val-Loss: 1.0589 target_val-Acc: 0.4513, Cost 0.4 sec
08-30 22:31:58 -----Epoch 5/49-----
08-30 22:31:58 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
Isc recall: 0
08-30 22:32:01 Epoch: 5 source_train-Loss: 1.0666 source_train-Acc: 0.4389, Cost 3.0 sec
08-30 22:32:01 Epoch: 5 source_val-Loss: 1.0665 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:01 Epoch: 5 target_val-Loss: 1.0542 target_val-Acc: 0.4496, Cost 0.4 sec
08-30 22:32:01 -----Epoch 6/49-----
08-30 22:32:01 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:04 Epoch: 6 source_train-Loss: 1.0661 source_train-Acc: 0.4392, Cost 3.0 sec
08-30 22:32:04 Epoch: 6 source_val-Loss: 1.0649 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:05 Epoch: 6 target_val-Loss: 1.0561 target_val-Acc: 0.4490, Cost 0.4 sec
08-30 22:32:05 -----Epoch 7/49-----
08-30 22:32:05 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:08 Epoch: 7 source_train-Loss: 1.0662 source_train-Acc: 0.4387, Cost 2.9 sec
08-30 22:32:08 Epoch: 7 source_val-Loss: 1.0666 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:08 Epoch: 7 target_val-Loss: 1.0583 target_val-Acc: 0.4500, Cost 0.4 sec
08-30 22:32:08 -----Epoch 8/49-----
08-30 22:32:08 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:11 Epoch: 8 source_train-Loss: 1.0662 source_train-Acc: 0.4398, Cost 2.8 sec
08-30 22:32:11 Epoch: 8 source_val-Loss: 1.0644 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:12 Epoch: 8 target_val-Loss: 1.0547 target_val-Acc: 0.4502, Cost 0.4 sec
08-30 22:32:12 -----Epoch 9/49-----
08-30 22:32:12 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:14 Epoch: 9 source_train-Loss: 1.0653 source_train-Acc: 0.4392, Cost 2.7 sec
08-30 22:32:15 Epoch: 9 source_val-Loss: 1.0645 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:15 Epoch: 9 target_val-Loss: 1.0530 target_val-Acc: 0.4515, Cost 0.4 sec
08-30 22:32:15 -----Epoch 10/49-----
08-30 22:32:15 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:18 Epoch: 10 source_train-Loss: 1.0649 source_train-Acc: 0.4389, Cost 2.8 sec
08-30 22:32:18 Epoch: 10 source_val-Loss: 1.0652 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:19 Epoch: 10 target_val-Loss: 1.0566 target_val-Acc: 0.4509, Cost 0.4 sec
08-30 22:32:19 -----Epoch 11/49-----
08-30 22:32:19 current lr: [0.001, 0.001, 0.001]
08-30 22:32:21 Epoch: 11 [4992/6568], Train Loss: 1.0650 Train Acc: 0.4370,1915.5 examples/sec 0.07 sec/batch
08-30 22:32:21 Epoch: 11 source_train-Loss: 1.0654 source_train-Acc: 0.4392, Cost 2.8 sec
08-30 22:32:22 Epoch: 11 source_val-Loss: 1.0645 source_val-Acc: 0.4389, Cost 0.2 sec
Isc recall: 0
08-30 22:32:22 Epoch: 11 target_val-Loss: 1.0528 target_val-Acc: 0.4517, Cost 0.4 sec
08-30 22:32:22 -----Epoch 12/49-----
08-30 22:32:22 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:25 Epoch: 12 source_train-Loss: 1.0659 source_train-Acc: 0.4387, Cost 2.8 sec
08-30 22:32:25 Epoch: 12 source_val-Loss: 1.0648 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:25 Epoch: 12 target_val-Loss: 1.0559 target_val-Acc: 0.4498, Cost 0.4 sec
08-30 22:32:25 -----Epoch 13/49-----
08-30 22:32:25 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:28 Epoch: 13 source_train-Loss: 1.0655 source_train-Acc: 0.4390, Cost 2.8 sec
08-30 22:32:28 Epoch: 13 source_val-Loss: 1.0643 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:29 Epoch: 13 target_val-Loss: 1.0538 target_val-Acc: 0.4507, Cost 0.4 sec
08-30 22:32:29 -----Epoch 14/49-----
08-30 22:32:29 current lr: [0.001, 0.001, 0.001]
08-30 22:32:32 Epoch: 14 source_train-Loss: 1.0652 source_train-Acc: 0.4387, Cost 2.7 sec
08-30 22:32:32 Epoch: 14 source_val-Loss: 1.0642 source_val-Acc: 0.4389, Cost 0.2 sec
Isc recall: 0
08-30 22:32:32 Epoch: 14 target_val-Loss: 1.0547 target_val-Acc: 0.4490, Cost 0.4 sec
08-30 22:32:32 -----Epoch 15/49-----
08-30 22:32:32 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:35 Epoch: 15 source_train-Loss: 1.0633 source_train-Acc: 0.4389, Cost 2.7 sec
08-30 22:32:35 Epoch: 15 source_val-Loss: 1.0649 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:36 Epoch: 15 target_val-Loss: 1.0559 target_val-Acc: 0.4509, Cost 0.4 sec
08-30 22:32:36 -----Epoch 16/49-----
08-30 22:32:36 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:38 Epoch: 16 source_train-Loss: 1.0646 source_train-Acc: 0.4390, Cost 2.7 sec
08-30 22:32:38 Epoch: 16 source_val-Loss: 1.0657 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:39 Epoch: 16 target_val-Loss: 1.0540 target_val-Acc: 0.4505, Cost 0.4 sec
08-30 22:32:39 -----Epoch 17/49-----
08-30 22:32:39 current lr: [0.001, 0.001, 0.001]
08-30 22:32:42 Epoch: 17 source_train-Loss: 1.0651 source_train-Acc: 0.4398, Cost 2.7 sec
08-30 22:32:42 Epoch: 17 source_val-Loss: 1.0643 source_val-Acc: 0.4389, Cost 0.2 sec
Isc recall: 0
08-30 22:32:42 Epoch: 17 target_val-Loss: 1.0541 target_val-Acc: 0.4502, Cost 0.4 sec
08-30 22:32:42 -----Epoch 18/49-----
08-30 22:32:42 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:45 Epoch: 18 source_train-Loss: 1.0643 source_train-Acc: 0.4387, Cost 2.7 sec
08-30 22:32:45 Epoch: 18 source_val-Loss: 1.0644 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:46 Epoch: 18 target_val-Loss: 1.0544 target_val-Acc: 0.4511, Cost 0.4 sec
08-30 22:32:46 -----Epoch 19/49-----
08-30 22:32:46 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:48 Epoch: 19 source_train-Loss: 1.0641 source_train-Acc: 0.4389, Cost 2.8 sec
08-30 22:32:49 Epoch: 19 source_val-Loss: 1.0660 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:49 Epoch: 19 target_val-Loss: 1.0579 target_val-Acc: 0.4498, Cost 0.4 sec
08-30 22:32:49 -----Epoch 20/49-----
08-30 22:32:49 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:52 Epoch: 20 source_train-Loss: 1.0652 source_train-Acc: 0.4384, Cost 2.7 sec
08-30 22:32:52 Epoch: 20 source_val-Loss: 1.0645 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:52 Epoch: 20 target_val-Loss: 1.0552 target_val-Acc: 0.4507, Cost 0.4 sec
08-30 22:32:52 -----Epoch 21/49-----
08-30 22:32:52 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:55 Epoch: 21 source_train-Loss: 1.0649 source_train-Acc: 0.4393, Cost 2.7 sec
08-30 22:32:55 Epoch: 21 source_val-Loss: 1.0647 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:56 Epoch: 21 target_val-Loss: 1.0529 target_val-Acc: 0.4513, Cost 0.4 sec
08-30 22:32:56 -----Epoch 22/49-----
08-30 22:32:56 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:32:59 Epoch: 22 source_train-Loss: 1.0643 source_train-Acc: 0.4400, Cost 2.8 sec
08-30 22:32:59 Epoch: 22 source_val-Loss: 1.0642 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:32:59 Epoch: 22 target_val-Loss: 1.0537 target_val-Acc: 0.4517, Cost 0.4 sec
08-30 22:32:59 -----Epoch 23/49-----
08-30 22:32:59 current lr: [0.001, 0.001, 0.001]
08-30 22:33:01 Epoch: 23 [3456/6568], Train Loss: 1.0649 Train Acc: 0.4390,1923.2 examples/sec 0.07 sec/batch
Isc recall: 0
08-30 22:33:02 Epoch: 23 source_train-Loss: 1.0643 source_train-Acc: 0.4389, Cost 2.8 sec
08-30 22:33:02 Epoch: 23 source_val-Loss: 1.0643 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:33:03 Epoch: 23 target_val-Loss: 1.0532 target_val-Acc: 0.4515, Cost 0.4 sec
08-30 22:33:03 -----Epoch 24/49-----
08-30 22:33:03 current lr: [0.001, 0.001, 0.001]
08-30 22:33:05 Epoch: 24 source_train-Loss: 1.0651 source_train-Acc: 0.4384, Cost 2.9 sec
08-30 22:33:06 Epoch: 24 source_val-Loss: 1.0643 source_val-Acc: 0.4389, Cost 0.2 sec
Isc recall: 0
08-30 22:33:06 Epoch: 24 target_val-Loss: 1.0539 target_val-Acc: 0.4515, Cost 0.4 sec
08-30 22:33:06 -----Epoch 25/49-----
08-30 22:33:06 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
08-30 22:33:10 Epoch: 25 source_train-Loss: 2.1298 source_train-Acc: 0.4389, Cost 4.2 sec
08-30 22:33:11 Epoch: 25 source_val-Loss: 1.0642 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:33:11 Epoch: 25 target_val-Loss: 1.0543 target_val-Acc: 0.4517, Cost 0.4 sec
08-30 22:33:11 -----Epoch 26/49-----
08-30 22:33:11 current lr: [0.001, 0.001, 0.001]
08-30 22:33:15 Epoch: 26 source_train-Loss: 2.1501 source_train-Acc: 0.4386, Cost 4.2 sec
08-30 22:33:15 Epoch: 26 source_val-Loss: 1.0666 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:33:16 Epoch: 26 target_val-Loss: 1.0589 target_val-Acc: 0.4513, Cost 0.4 sec
08-30 22:33:16 -----Epoch 27/49-----
08-30 22:33:16 current lr: [0.001, 0.001, 0.001]
Isc recall: 0
Isc recall: 0
08-30 22:33:20 Epoch: 27 source_train-Loss: 2.1629 source_train-Acc: 0.4389, Cost 4.3 sec
08-30 22:33:20 Epoch: 27 source_val-Loss: 1.0668 source_val-Acc: 0.4389, Cost 0.2 sec
08-30 22:33:21 Epoch: 27 target_val-Loss: 1.0593 target_val-Acc: 0.4502, Cost 0.4 sec
08-30 22:33:21 -----Epoch 28/49-----
08-30 22:33:21 current lr: [0.001, 0.001, 0.001]
Traceback (most recent call last):
  File "E:\Galaxy\yang7hi_battery\train_base.py", line 133, in <module>
    trainer.train(cond=condition)
  File "E:\Galaxy\yang7hi_battery\utlis\train_utils_base.py", line 538, in train
    loss.backward()
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "D:\anaconda\envs\pytorch\lib\site-packages\torch\autograd\__init__.py", line 175, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: Function 'MulBackward0' returned nan values in its 1th output.